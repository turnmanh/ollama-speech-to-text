# Speech to LLM Interaction

Utilizing speech, processed via OpenAI's whisper, to interact with a language
model.

## TODOs

- [x] Add total time 
- [ ] Add time until first token 
- [ ] Add notes on the hardware used for comparison / disclaimer 
- [x] Add bold fonts to timing stats

### Specifically for Multi-Modal

- [ ] Add async + streaming
- [ ] Add history to vision model
